<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Niranjan's Portfolio</title>
    <link rel="stylesheet" href="style_project_2.css">
    <script src="https://kit.fontawesome.com/90171aec82.js" crossorigin="anonymous"></script>
</head>
<body>
    
<div id="header">
    <div class="container">
        <nav>
            <a href="index.html#header"><img src="images/logo.png" class="logo"></a>
            <ul class="menu" id="sidemenu">
                <li><a href="index.html#header">Home</a></li>
                <li><a href="index.html#about">About Me</a></li>
                <li><a href="index.html#projects">My Work</a>
                        <div class="sub-menu-1"> 
                            <ul>

                                <li class="sub-menu-2-hover"><a href="project1.html#header">Inventory Optimization (CSCI 5622)</a>
                                    <div class="sub-menu-2">
                                        <ul>
                                            <li><a href="project1.html#Introduction-Content">Introduction</a></li>
                                            <li><a href="project1.html#navigation-content">DataPrep_EDA</a></li>
                                            <li class="sub-menu-3-hover"><a href="project1.html#navigation-content">Modeling</a>
                                                <div class="sub-menu-3">
                                                    <ul>
                                                        <li><a href="project1.html#navigation-content">Clustering</a></li>
                                                        <li><a href="project1.html#navigation-content">ARM</a></li>
                                                        <li><a href="project1.html#navigation-content">Naïve Bayes</a></li>
                                                        <li><a href="project1.html#navigation-content">Decision Tree</a></li>
                                                        <li><a href="project1.html#navigation-content">SVMs</a></li>
                                                        <li><a href="project1.html#navigation-content">Regression</a></li>
                                                        <li><a href="project1.html#navigation-content">Neural Nets</a></li>
                                                    </ul>
                                                </div>                                        
                                            </li>
                                        </ul>
                                    </div>
                                </li>


                                <li class="sub-menu-2-hover"><a href="project2.html#header">B2C Brand Perception (INFO 5871)</a>
                                    <div class="sub-menu-2">
                                        <ul>
                                            <li><a href="#Introduction-Content" onclick="opentab('Introduction-Content')">Introduction</a></li>
                                            <li><a href="#Data-Preparation-Content" onclick="opentab('Data-Preparation-Content')">DataPrep</a></li>
                                            <li class="sub-menu-3-hover"><a href="#Clustering-Content" onclick="opentab('Clustering-Content')">Modeling</a>
                                                <div class="sub-menu-3">
                                                    <ul>
                                                        <li><a href="#Clustering-Content" onclick="opentab('Clustering-Content')">Clustering</a></li>
                                                        <li><a href="#LDA-Content" onclick="opentab('LDA-Content')">LDA</a></li>
                                                        <li><a href="#ARM-Content" onclick="opentab('ARM-Content')">ARM</a></li>
                                                    </ul>
                                                </div>
                                            </li>
                                        </ul>
                                    </div>
                                </li>


                                <li class="sub-menu-2-hover"><a href="project3.html#header">Dock Watch (CSCI 5502)</a>
                                    <div class="sub-menu-2">
                                        <ul>
                                            <li><a href="project3.html#Introduction-Content">Introduction</a></li>
                                            <li><a href="project3.html#navigation-content">Data Preparation</a></li>
                                            <li><a href="project3.html#navigation-content">Data Exploration</a></li>
                                            <li><a href="project3.html#navigation-content">Modeling</a></li>
                                        </ul>
                                    </div>
                                </li>


                            </ul>
                        </div>                
                    </li>               
                </li>
                <li><a href="index.html#contact">Contact</a></li>
                <i class="fas fa-times" onclick="closemenu()"></i>
            </ul>
            <i class="fas fa-bars" onclick="openmenu()"></i>
        </nav>
        <div class="header-text" style="padding-top: 3%;">
            <h1>B2C Brand Perception Analysis</h1>
        </div>
    </div>
</div>

<!-- -----------Project Contents---------- -->
<div class="container" id="navigation-content">
    <div class="tab-titles" >
        <p class="tab-links active-link" onclick="opentab('Introduction-Content')">Introduction</p>
        <p class="tab-links" onclick="opentab('Data-Preparation-Content')">Data Collection & Preparation</p>
        <p class="tab-links" onclick="opentab('Clustering-Content')">Clustering</p>
        <p class="tab-links" onclick="opentab('LDA-Content')">LDA</p>
        <p class="tab-links" onclick="opentab('ARM-Content')">ARM</p>
    </div>

    <div class="tab-contents active-tab" id="Introduction-Content">
        <div class="intro">
            <h1 class="sub-title">Introduction</h1>
            <br><br>
            <p>On an average, a company allocates approximately 9.1% of its revenue to marketing (<a href="https://vitaldesign.com/percent-of-revenue-spent-on-marketing-sales/#:~:text=Businesses%20large%20and%20small%20understand,12.1%25%20across%20industries%20in%202016." target="_blank">source</a>), with a significant portion directed towards campaign planning & content creation (40-50%), paid advertising (20-30%), and the rest on workforce marketing and events. (<a href="https://business.adobe.com/blog/basics/a-high-level-b2b-marketing-budget-breakdown" target="_blank">source</a>). But what is the purpose of investing not only so much money, but also a lot of time and effort, into marketing?</p>
            <br>
            <p>The current market is vast, and regardless of the industry, every company faces thousands of competitors. In such an era, it is crucial to stay ahead and build a good perception among consumers in order to succeed. One of the best ways to understand the importance of brand perception is through McKinsey’s Consumer Decision Journey chart:</p>
            <br>
            <img src="images/b2c_intro1.png" class= "intro-quote">
            <br>
            <P>This chart clearly shows the decision cycle of a consumer starting from the consideration to brand advocacy. While each state is crucial, the Evaluation and Advocacy stage plays an upper hand:</P>
            <br>
            <ul>
                <li style="list-style: circle;">Evaluation stage is when consumers research to make an informed decision. Where they collect information from their own, ask friends, read public opinions, etc and make a final decision to engage further or not.</li>
                <li style="list-style: circle;">Advocacy stage is when a consumer gets into the loyalty loop and advocate for the brand’s services/ products.</li>
            </ul>
            <br>
            <p>These 2 stages play an important role in a company’s success, retaining existing customers and gaining new customers as word of mouth is the most powerful source for any customer. Therefore, significant marketing efforts has been put globally to ensure a brand has a loyal set of customers advocating for it.</p>
            <br>
            <img src="images/b2c_intro2.png" class= "intro-quote">
            <br>
            <p>Now that we know it is important, we can also realize that it is importance of measuring a brand’s perception, right? But the question is how?</p>
            <br>
            <p>In the past, measuring brand perception was challenging and required a lot of manual investigation. However, in today’s digital age, where customers opinions are readily available all over the internet. It is easy to find both sided perspective about a any brand online. So, if one can harness the power of these opinions by building a framework capable of collecting data about a brand across the web, analysing them and providing insights on to the area of improvement, it’d be a success for the company to measure it’s customer perception and tailor their marketing strategies according.</p>
            <br>
            <p>However, it's important to note that most consumers tend to write reviews when they are dissatisfied. Therefore, there’s a high possibility that the data collected from the online sites may not represents both sides equally. Nevertheless, the primary goal remains understanding the customer's point of view and identifying opportunities for improvement, making the skewed data less significant.</p>
            <br>
            <p>Ultimately, this framework can be used to measure:</p>
            <ul>
                <li style="list-style: circle;">Brand's reach based on number of reviews.</li>
                <li style="list-style: circle;">Brand's perception through customer review sentiment.</li>
                <li style="list-style: circle;">Brand's perception across various categories such as quality, customer support, shipping, returns, service, value for money, etc.</li>
                <li style="list-style: circle;">Brand perception shift over time, especially after a major marketing campaign or decision.</li>
            </ul>
        </div>
    </div>

    <div class="tab-contents" id="Data-Preparation-Content">
        <div class="intro">
            <h1 class="sub-title">Data Collection</h1>
            <br><br>
            <p>Though the goal is to build a dynamic framework capable of analyzing the brand perception of any chosen company. To construct and validate this framework, an initial sample dataset has been compiled from various sources. The chosen sample is a well-recognized ride-hailing service company, "<b>Uber</b>" and the collected data is a combination of customer reviews, recent news articles, and Reddit posts. Find more information regarding the data collection process below. </p>
            <br><br>

            <h3>Source 1: Trustpilot</h3>
            <br><br>
            <p>Trustpilot is a free public review platform featuring diverse reviews from customers. Data from Trustpilot were <b>web scrapped using the Beautiful Soup python library</b>. In addition to customer reviews, the following information were also scrapped from the website to ensure the analysis be presented across multiple dimensions:</p>
            <br>
            <ol>
                <li>Reviewer Name</li>
                <li>Reviewer Total Reviews</li>
                <li>Location</li>
                <li>Review Star Rating</li>
                <li>Review Title</li>
                <li>Review</li>
                <li>Date</li>
                <li>Review Likes</li>
            </ol>
            <img src="images/b2c_source1.PNG" style="max-width: 90%; align-items:center; height: auto;margin: 0 auto; display: block; " >
            <br>
            <p>Find the data collection code <a href="https://github.com/Niranjan-Cholendiran/B2C-Brand-Perception-Analysis/blob/main/01_Data_Collection/01_TrustPilot_WebScrape.ipynb" target="_blank">here</a></p>
            <p>Download the raw data <a href="https://drive.google.com/drive/folders/1ePnv1q3zAfQiU-iUNK3ku6prUV0-J5Kl?usp=sharing" target="_blank">here</a></p>
            <br>


            
            <h3>Source 2: NewsAPI</h3>
            <br><br>
            <p>While customer reviews offer a great source to measure brand perception. It is also crucial to keep track of public news, especially the popular ones, to analyse the current pulse of market and potential areas of improvement. Hence, NewsAPI were used to collect recent popular news articles tagged on the company “Uber”. The data were collected on the following topics individually:</p>
            <br>
            <ol>
                <li>Customer Service</li>
                <li>Safety</li>
                <li>Promotions</li>
                <li>Pricing</li>
            </ol>
            
            <br>
            <h4>API Components:</h4>
            <br>
            <ul>
                <li>1. Endpoint: <i>https://newsapi.org/v2/everything</i></li>
                <li>2. Parameters:</li>
                <ul>
                    <li>q: <i>uber%20NOT%20eats%20AND%20[topic]</i></li>
                    <li>language: <i>en</i></li>
                    <li>apiKey: <i>[API KEY]</i></li>
                    <li>sortby: <i>popularity</i></li>
                </ul>
            </ul>
            <img src="images/b2c_source2.PNG" style="max-width: 90%; align-items:center; height: auto;margin: 0 auto; display: block; " >
            <br>
            <p>Find the data collection code <a href="https://github.com/Niranjan-Cholendiran/B2C-Brand-Perception-Analysis/blob/main/01_Data_Collection/02_NewsAPI_Data_Collection.ipynb" target="_blank">here</a></p>
            <p>Download the raw data <a href="https://drive.google.com/drive/folders/1ePnv1q3zAfQiU-iUNK3ku6prUV0-J5Kl?usp=sharing" target="_blank">here</a></p>
            <br>

            <h3>Source 3: Reddit</h3>
            <br><br>
            <p>In addition to customer reviews and news articles, social network contents from Reddit was also collected to monitor the company’s campaigns and promotions- which could potentially influence and shift customers perception. Reddit API were used for this purpose.</p>
            <br>
            <h4>API Components:</h4>
            <br>
            <ul>
                <li>1. Endpoint: <i>https://oauth.reddit.com/r/[subreddit]/new</i></li>
                <li>2. Parameters:</li>
                <ul>
                    <li>subreddit: <i>Uber</i></li>
                    <li>g: <i>en</i></li>
                    <li>authentication: <i>[AUTHENTICATION TOKEN]</i></li>
                    <li>sortby: <i>popularity</i></li>
                </ul>
            </ul>
            <img src="images/b2c_source3.PNG" style="max-width: 90%; align-items:center; height: auto;margin: 0 auto; display: block; " >
            <br>
            <p>Find the data collection code <a href="https://github.com/Niranjan-Cholendiran/B2C-Brand-Perception-Analysis/blob/main/01_Data_Collection/03_Reddit_Auth_and_Data_Collection.ipynb" target="_blank">here</a></p>
            <p>Download the raw data <a href="https://drive.google.com/drive/folders/1ePnv1q3zAfQiU-iUNK3ku6prUV0-J5Kl?usp=sharing" target="_blank">here</a></p>



            <br><br>
            <h1 class="sub-title">Data Preparation</h1>
            <br><br>
            <p>The collected raw data contains a combination of text, categorical and numerical features. However, it cannot be used directly for analysis, especially the text data. Hence, the data has been pre-processed in a was that can be used for modeling. The following are a few data cleaning steps performed on the raw data.</b></p>
            <br>
                
            <h4>Data Preparation Steps:</h4>
            <ul>
                <li>1. Unique identifier creation:</i>
                    <ul>
                        <li>Every review was tagged to an unique ID to ensure traceability throughout the analysis.</li>
                    </ul>
                    <img src="images/b2c_dataprep1.PNG" style="max-width: 90%; align-items:center; height: auto;margin: 0 auto; display: block; " >
                </li>
                <br>

                <li>2. Filtering:</i>
                    <ul>
                        <li>The dataset includes reviews from around the world dating back over 10 years. To focus on recent feedback and ensure relevance, the data is filtered out for the last 3 years from the United States.</li>
                    </ul>
                </li>
                <br>

                <li>3. Removed special characters and numbers:</i>
                    <ul>
                        <li>Along with texts, the reviews were a mix of punctuations, emojis and numbers, which are not required in this use case. Hence, they were removed from the dataset.</li>
                    </ul>
                    <img src="images/b2c_dataprep3.png" style="max-width: 90%; align-items:center; height: auto;margin: 0 auto; display: block; " >
                </li>
                <br>

                <li>4. Lemmatization:</i>
                    <ul>
                        <li>The words were lemmatized to ensure different forms of a same word are treated identically</li>
                    </ul>
                    <img src="images/b2c_dataprep4.png" style="max-width: 90%; align-items:center; height: auto;margin: 0 auto; display: block; " >
                </li>
                <br>

                <li>5. Stop words Removal:</i>
                    <ul>
                        <li>The reviews included words that lacked contextual relevance; hence they were removed from the texts. Along with NLTK’s inbuilt stop words, a few self-defined stop words like “Uber” and “Driver” were also removed.</li>
                    </ul>
                    <img src="images/b2c_dataprep5.png" style="max-width: 90%; align-items:center; height: auto;margin: 0 auto; display: block; " >
                </li>
                <br>
                <li>6. TFIDF Vectorization:</i>
                    <ul>
                        <li>Finally, the words have been vectorized by calculating the frequency and normalizing them.</li>
                        <li>Max_df of 0.7 has been applied ensure removal of content specific stop words.</li>
                    </ul>
                    <img src="images/b2c_dataprep6.png" style="max-width: 90%; align-items:center; height: auto;margin: 0 auto; display: block; " >
                </li>
            </ul>
                <br>
        
            <h4>Word Cloud before and after cleaning:</h4>
                <img src="images/b2c_dataprep7.png" style="max-width: 90%; align-items:center; height: auto;margin: 0 auto; display: block; " >
        <br>
        <p>Find the data preprocessing code <a href="https://github.com/Niranjan-Cholendiran/B2C-Brand-Perception-Analysis/blob/main/01_Data_Preparation/Data_Cleaning.ipynb" target="_blank">here</a></p>
        <p>Download the preprocessed data <a href="https://drive.google.com/drive/folders/1LRSoqRIfiOYIubV9_JjoJozAj-UUQzzV?usp=drive_link" target="_blank">here</a></p>

        </div>
    </div>

    <div class="tab-contents" id="Clustering-Content">
        <div class="intro">
            <h1 class="sub-title">Clustering</h1>
            <br><br>
            <p>Clustering is as an unsupervised learning method in machine learning, dividing data based on feature distances. Its goal is to group similar records within clusters (cohesion) while maintaining dissimilarity from objects in other clusters (separation). There are multiple ways to implement clustering however the most popular implementation includes K-Means and Hierarchical Clustering.</p>
            <br>
            <p><b>K-Means Clustering: </b>This partitioning technique clusters data into a set number of clusters by aggregating the K closest points to a designated point. Various distance metrics (Euclidean, Manhattan, etc.) can be utilized based on the context.</b></p>
            <img src="images/clustering_kmeans.png" class= "DataPrep-Step" style="max-width: 65%;">
            <br>
            <p><b>Hierarchical Clustering: </b>This method organizes data hierarchically, constructing dendrogram tree structures. Agglomerative clustering starts with the assumption that each point forms its own cluster, gradually merging them until ideally only one cluster remains. Similar to K-Means, diverse distance metrics and linkage methods are available, chosen according to the specific case.</b></p>
            <img src="images/clustering_hier.png" class= "DataPrep-Step" style="max-width: 30%;">
            <br>
            <p>For this application, both clustering and hierarchical clustering are applied to group similar review based on the frequency of common words.</b></p>
            <br>
            <h3>Data Preparation</h3>
            <br><br>
            <p>Both K-Means and Hierarchical clustering needs numerical data to cluster. Therefore, the document term matrix that was preprepared in the previous section was used. The document term matrix is a review number- document matrix with the values as TFIDF normalized frequencies.</b></p>
            <br>
            <img src="images/b2c_docterm.PNG" class= "DataPrep-Step" style="max-width: 100%;">
            <br>
            <p>Download the data <a href="https://drive.google.com/file/d/1oIyPIhHV1HQ244Q_wC0VUB12GXZVAb0s/view?usp=sharing" target="_blank">here</a></p>
            <br>
            <h3>Experiment Setup & Results</h3>
            <br>

            <h4>Hierarchical Clustering:</h4><br>
            <ol>
                <li>Determining the Optimal Number of Clusters:</li><br>
                <p>The Elbow method and Silhouette method were utilized to identify the optimal cluster count:</p>
                <br><img src="images/b2c_hclust_optimalclusters.PNG" class= "DataPrep-Step" style="max-width: 70%;"><br>
                <p>Both methods suggested two clusters as optimal.</p>
                <br>

                <li>Agglomerative clustering implementation:</li><br>
                <p>Hierarchical clusters were computed using Cosine Similarity distance metric, and Ward linkage method. The dendogram of the result is displayed below:</p>
                <br>
                <img src="images/b2c_hclust_dendo.png" class= "DataPrep-Step" style="max-width: 80%;">
                <br>
            </ol>
            <br>
            <p>Find the hierarchical clustering R script <a href="https://github.com/Niranjan-Cholendiran/B2C-Brand-Perception-Analysis/blob/main/02_Clustering/Hierarchical_Clustering.Rmd" target="_blank">here</a></p>
            <br>

            <h4>K-Means Clustering:</h4><br>
            <ol>
                <li>Determining the Optimal Number of Clusters:</li><br>
                <p>Both the Elbow method and Silhouette method were used to find the optimal cluster count.</p>
                <br><img src="images/b2c_kmeans_optimalclusters.PNG" class= "DataPrep-Step" style="max-width: 70%;">
                <p>Both methods suggested two number of clusters. However, 3 and 4 clusters were also computed for comparison.</p>
                <br>

                <li>K-Means implementation:</li><br>
                <p>K-Means clustering with 2, 3 and 4 clusters using Euclidean distance was performed and the word clouds of each clusters were computed.</p>
                <br>
                <br><img src="images/b2c_kmeans_results1.PNG" class= "DataPrep-Step" style="max-width: 100%;">
                <br><img src="images/b2c_kmeans_results2.PNG" class= "DataPrep-Step" style="max-width: 100%;">

                <p>Find the K-Means clustering Python script <a href="https://github.com/Niranjan-Cholendiran/B2C-Brand-Perception-Analysis/blob/main/02_Clustering/K-Means.ipynb" target="_blank">here</a></p>
                <br>
            </ol>
            <br>
            
            <h3>Inference & Conclusion</h3>
            <br>
            <p>Both K-Means and Hierarchical clustering have effectively organized the data, displaying a similar distribution across clusters with minimal discrepancies. Almost all clusters have overlapping words due to the high frequency of selected words in the corpus. <b>This is a clear indicator that clustering reviews only based on similar words is insufficient.</b> Hence, a topic modeling alogrithm has been explored in the next section.</p>
            <br>
        </div>
    </div>



    <div class="tab-contents" id="LDA-Content">
        <div class="intro">
            <h1 class="sub-title">Latent Dirichlet Allocation (LDA)</h1>
            <br><br>
            <p>LDA is a topic modeling algorithm that is based on probabilistic modeling. In short, it assumes that each document in a corpus is a mixture of various topics, and each topic is a distribution over words. The goal of LDA is to discover these underlying topics based on the words that appear in the documents. In this project, the aim is to group reviews based on the underlying topics. </p> 

            <br><img src="images/b2c_lda_intro.PNG" class= "DataPrep-Step" style="max-width: 70%;">
            <br>

            <h3>Data Preparation</h3>
            <br><br>
            <p>LDA needs frequency of words data. Therefore, the document term matrix that was preprepared in the previous sections was used. The document term matrix is a review number- document matrix with the values as TFIDF normalized frequencies.</b></p>
            <br>
            <img src="images/b2c_docterm.PNG" class= "DataPrep-Step" style="max-width: 100%;">
            <br>
            <p>Download the data <a href="https://drive.google.com/file/d/1oIyPIhHV1HQ244Q_wC0VUB12GXZVAb0s/view?usp=sharing" target="_blank">here</a></p>
            <br>


            <h3>Experiment Setup & Results</h3>
            <br>
            <p>LDA for 2, 3, 4 and 5 topics were performed for comparison. The results of each experiment is listed below:</p>
            <img src="images/b2c_lda_topics_results.PNG" class= "DataPrep-Step" style="max-width: 80%;">
            <br>
            <p>Out of the above four topic modelling results, the one with 4 topics seems reasonable. Find the detailed result below:</p>

            <div style="text-align: center;">
                <iframe width="1200" height="600" src='external_html/b2c_lda_output.html'></iframe>
            </div>




            <br>
            <p>Find the LDA Python script <a href="https://github.com/Niranjan-Cholendiran/B2C-Brand-Perception-Analysis/blob/main/03_LDA/01.%20LDA_Code.ipynb" target="_blank">here</a></p>
            <br>
            <h3>Conclusion</h3><br>
            <p>Out of the above four topic modelling results, the one with 4 topics seems reasonable. Find the </p>
            <br>

            <b>Topic 1: Service Quality and Comfort</b>
            <ul><li>This topic may be discussing the quality of service provided by Uber drivers, focusing on aspects like cleanliness of vehicles, friendliness of drivers, professionalism, and overall comfort of the ride experience.</li></ul>

            <b>Topic 2: Issues with Service and Payments</b>
            <ul><li>This topic may be discussing the quality of service provided by Uber drivers, focusing on aspects like cleanliness of vehicles, friendliness of drivers, professionalism, and overall comfort of the ride experience.</li></ul>

            <b>Topic 3: Feedback on Convenience and Reliability</b>
            <ul><li>This topic likely discusses feedback on the convenience and reliability of Uber service, including discussions about fast and smooth rides, scheduling options, transportation choices, and experiences outside or on the road.</li></ul>

            <b>Topic 4: Positive Experience and Appreciation</b>
            <ul><li>This topic likely revolves around positive experiences and appreciation for Uber service, highlighting ease of use, excellent service, friendliness of drivers, and overall satisfaction with the experience.</li></ul>
            <br>
            <br>
            <p><b>Next Steps:</b> Alternatelively, a method to achieve topic modeling based on the topic of interest rather than emotions can be explored. For example,</p>
            <ul>   
                <li>Sentence 1: "I was happy about the early pickup"</li>
                <li>Sentence 2: "I was happy about how the car was comfortable"</li>
                <li>Sentence 3: "I hated the ride. The ride was discomforting."</li>
            </ul>
            <p>Sentence 1 and 2 should not be grouped (because they have same emotion), rather 2 and 3 should be together because they talk about ride quality. This could be achieved by removing the sentiment related words prior to LDA. NLTK's SentimentIntensityAnalyzer could be a good start.</p>
        </div>
    </div>

    <div class="tab-contents" id="ARM-Content">
        <div class="intro">
            <h1 class="sub-title">Association Rule Mining</h1>
            <br><br>
            <p>Association Rule Mining (ARM) is an unsupervised machine learning method used to discover patterns and association in a transaction data. The goal is to typically identify relationships between the itemset in the format <b>{Antecedent}</b> -> <b>{Consequent}</b>. ARM is computed using three key measures:</p>
            <br><img src="images/ARM_intro_1.png" class= "DataPrep-Step" style="max-width: 70%;">
            <br>
            <ol>
                <li>Support:
                    <ul>
                        <li>It is the frequency of an item/ itemset occurred in the entire sale. It is more like the prior probability. o	Low support signifies that the product is not purchased by sufficient # people to apply association rules.</li>
                    </ul>
                </li>
                <li>Confidence:</li>
                    <ul>
                        <li>Defines the level of confidence that Consequents will be bought when Antecedent is bought already. It is more like a conditional probability. o	Low confidence signifies that consequent is independent of antecedent and no association exist between them.</li>
                    </ul>
                <li>Lift:</li>
                    <ul>
                        <li>Defines how much the probability of buying consequent is lifted when purchased along with antecedent rather just buying them independently. Always, Confidence > Support (Lift > 1) is ideal as it signifies that buying Antecedent lifts the purchase of Consequent. It is conditional probability divided by prior probability.</li>
                    </ul>
            </ol>
            <br><img src="images/ARM_intro_2.png" class= "DataPrep-Step" style="max-width: 70%;">
            <br>
            <p>Apriori stands as a widely utilized association rule mining (ARM) technique rooted in the fundamental principle: "If an itemset is frequent, then all of its subsets must also be frequent." Leveraging this property, ARM efficiently prunes item sets with low support, thereby minimizing the search space. In this project, we're using the Apriori algorithm to find the combination of words that occurs together frequently in the reviews. <b>The goal is to figure out which word's frequency is lifted by other words, giving us insights into customer's perception on each topics.</b></p>
            <br>
            <h3>Data Preparation</h3><br>
            <p>Unlike other machine learning algorithms, ARM is used with unlabelled transactional data. Hence, the reviews are preprocessed by removing stop words and lemmatizing them, and converted to basket format.</p>
            <br>
            <img src="images/b2c_arm_dataprep.PNG" class= "DataPrep-Step" style="max-width: 80%;">
            <br>
            <p>Find the data preparation Python script <a href="https://github.com/Niranjan-Cholendiran/B2C-Brand-Perception-Analysis/blob/main/04_ARM/basket_data_prep.ipynb" target="_blank">here</a></p>
            <p>Download the data <a href="https://drive.google.com/file/d/1vwLcIdwYb6EYWwWCFdPutHpPSanpjPiN/view?usp=sharing" target="_blank">here</a></p>
            <br>

            <h3>Experiment Setup & Results</h3><br>
            <p>Apriori algorithm was used to extract rules from the dataset for the below combinations:</p>
            <ul>
                <li style="list-style-type: circle">Minimum Support: 0.3%</li>
                <li style="list-style-type: circle">Confidence: 0.5%</li>
            </ul>
            <p>The item sets with top 10 support, confidence and lift are displayed below along with it's network representation.</p>
            <br>
            <img src="images/b2c_arm_results.PNG" class= "DataPrep-Step" style="max-width: 80%;">
            <div style="text-align: center;">
                <iframe width="800" height="600" src='external_html/b2c_arm_interactive_plot.html'></iframe>
            </div>
            <img src="images/b2c_arm_network_graph.png" class= "DataPrep-Step" style="max-width: 50%;">
            <br>
            <p>Find the ARM implementation R script <a href="https://github.com/Niranjan-Cholendiran/B2C-Brand-Perception-Analysis/blob/main/04_ARM/ARM.Rmd" target="_blank">here</a></p>
            <br>

            <h3>Conclusion</h3><br>
            <p>ARM results are not straight forward and not every rule represents a topic, however it indicates that many customers have written about the cleanliness of the vehicle and customer service.</p>
            <br>
        </div>
    </div>

</div>

<div class="copyright" id="copyright">
</div>

<script>

    var tablinks = document.getElementsByClassName("tab-links");
    var tabcontents = document.getElementsByClassName("tab-contents");

    function opentab(tabname){
        for(tablink of tablinks){
            tablink.classList.remove("active-link");
        }
        for(tabcontent of tabcontents){
            tabcontent.classList.remove("active-tab");
        }
        event.currentTarget.classList.add("active-link");
        document.getElementById(tabname).classList.add("active-tab");
    }

</script>


</body>
</html>